# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Apple
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.27\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:54+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/usage/unified_memory.rst:4
msgid "Unified Memory"
msgstr ""

#: ../../../src/usage/unified_memory.rst:8
msgid ""
"Apple silicon has a unified memory architecture. The CPU and GPU have direct "
"access to the same memory pool. MLX is designed to take advantage of that."
msgstr ""

#: ../../../src/usage/unified_memory.rst:11
msgid ""
"Concretely, when you make an array in MLX you don't have to specify its "
"location:"
msgstr ""

#: ../../../src/usage/unified_memory.rst:14
msgid ""
"a = mx.random.normal((100,))\n"
"b = mx.random.normal((100,))"
msgstr ""

#: ../../../src/usage/unified_memory.rst:19
msgid "Both ``a`` and ``b`` live in unified memory."
msgstr ""

#: ../../../src/usage/unified_memory.rst:21
msgid ""
"In MLX, rather than moving arrays to devices, you specify the device when "
"you run the operation. Any device can perform any operation on ``a`` and "
"``b`` without needing to move them from one memory location to another. For "
"example:"
msgstr ""

#: ../../../src/usage/unified_memory.rst:25
msgid ""
"mx.add(a, b, stream=mx.cpu)\n"
"mx.add(a, b, stream=mx.gpu)"
msgstr ""

#: ../../../src/usage/unified_memory.rst:30
msgid ""
"In the above, both the CPU and the GPU will perform the same add operation. "
"The operations can (and likely will) be run in parallel since there are no "
"dependencies between them. See :ref:`using_streams` for more information the "
"semantics of streams in MLX."
msgstr ""

#: ../../../src/usage/unified_memory.rst:35
msgid ""
"In the above ``add`` example, there are no dependencies between operations, "
"so there is no possibility for race conditions. If there are dependencies, "
"the MLX scheduler will automatically manage them. For example:"
msgstr ""

#: ../../../src/usage/unified_memory.rst:39
msgid ""
"c = mx.add(a, b, stream=mx.cpu)\n"
"d = mx.add(a, c, stream=mx.gpu)"
msgstr ""

#: ../../../src/usage/unified_memory.rst:44
msgid ""
"In the above case, the second ``add`` runs on the GPU but it depends on the "
"output of the first ``add`` which is running on the CPU. MLX will "
"automatically insert a dependency between the two streams so that the second "
"``add`` only starts executing after the first is complete and ``c`` is "
"available."
msgstr ""

#: ../../../src/usage/unified_memory.rst:51
msgid "A Simple Example"
msgstr ""

#: ../../../src/usage/unified_memory.rst:53
msgid ""
"Here is a more interesting (albeit slightly contrived example) of how "
"unified memory can be helpful. Suppose we have the following computation:"
msgstr ""

#: ../../../src/usage/unified_memory.rst:56
msgid ""
"def fun(a, b, d1, d2):\n"
"  x = mx.matmul(a, b, stream=d1)\n"
"  for _ in range(500):\n"
"      b = mx.exp(b, stream=d2)\n"
"  return x, b"
msgstr ""

#: ../../../src/usage/unified_memory.rst:64
msgid "which we want to run with the following arguments:"
msgstr ""

#: ../../../src/usage/unified_memory.rst:66
msgid ""
"a = mx.random.uniform(shape=(4096, 512))\n"
"b = mx.random.uniform(shape=(512, 4))"
msgstr ""

#: ../../../src/usage/unified_memory.rst:71
msgid ""
"The first ``matmul`` operation is a good fit for the GPU since it's more "
"compute dense. The second sequence of operations are a better fit for the "
"CPU, since they are very small and would probably be overhead bound on the "
"GPU."
msgstr ""

#: ../../../src/usage/unified_memory.rst:75
msgid ""
"If we time the computation fully on the GPU, we get 2.8 milliseconds. But if "
"we run the computation with ``d1=mx.gpu`` and ``d2=mx.cpu``, then the time "
"is only about 1.4 milliseconds, about twice as fast. These times were "
"measured on an M1 Max."
msgstr ""

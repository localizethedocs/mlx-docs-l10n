# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, MLX Contributors
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.4\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:56+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/index.rst:28
msgid "Install"
msgstr "安裝"

#: ../../../src/index.rst:34
msgid "Usage"
msgstr "使用方式"

#: ../../../src/index.rst:48
msgid "Examples"
msgstr "範例"

#: ../../../src/index.rst:56
msgid "Python API Reference"
msgstr "Python API 參考"

#: ../../../src/index.rst:71
msgid "C++ API Reference"
msgstr "C++ API 參考"

#: ../../../src/index.rst:77
msgid "Further Reading"
msgstr "延伸閱讀"

#: ../../../src/index.rst:2
msgid "MLX"
msgstr "MLX"

#: ../../../src/index.rst:4
msgid ""
"MLX is a NumPy-like array framework designed for efficient and flexible "
"machine learning on Apple silicon, brought to you by Apple machine learning "
"research."
msgstr ""
"MLX 是一個類似 NumPy 的陣列框架，為 Apple 晶片上的高效且靈活的機器學習而設"
"計，由 Apple 機器學習研究團隊提供。"

#: ../../../src/index.rst:7
msgid ""
"The Python API closely follows NumPy with a few exceptions. MLX also has a "
"fully featured C++ API which closely follows the Python API."
msgstr ""
"Python API 幾乎完全遵循 NumPy，只有少數例外。MLX 也提供功能完整的 C++ API，同"
"樣緊密遵循 Python API。"

#: ../../../src/index.rst:10
msgid "The main differences between MLX and NumPy are:"
msgstr "MLX 與 NumPy 之間的主要差異為："

#: ../../../src/index.rst:12
msgid ""
"**Composable function transformations**: MLX has composable function "
"transformations for automatic differentiation, automatic vectorization, and "
"computation graph optimization."
msgstr ""
"**可組合的函式轉換**：MLX 提供可組合的函式轉換，用於自動微分、自動向量化，以"
"及計算圖最佳化。"

#: ../../../src/index.rst:15
msgid ""
"**Lazy computation**: Computations in MLX are lazy. Arrays are only "
"materialized when needed."
msgstr "**惰性計算**：MLX 中的計算採惰性方式，陣列只在需要時才會實體化。"

#: ../../../src/index.rst:17
msgid ""
"**Multi-device**: Operations can run on any of the supported devices (CPU, "
"GPU, ...)"
msgstr "**多裝置**：運算可以在任何支援的裝置（CPU、GPU 等）上執行。"

#: ../../../src/index.rst:20
msgid ""
"The design of MLX is inspired by frameworks like `PyTorch <https://pytorch."
"org/>`_, `Jax <https://github.com/google/jax>`_, and `ArrayFire <https://"
"arrayfire.org/>`_. A notable difference from these frameworks and MLX is the "
"*unified memory model*. Arrays in MLX live in shared memory. Operations on "
"MLX arrays can be performed on any of the supported device types without "
"performing data copies. Currently supported device types are the CPU and GPU."
msgstr ""
"MLX 的設計靈感來自 `PyTorch <https://pytorch.org/>`_、`Jax <https://github."
"com/google/jax>`_ 與 `ArrayFire <https://arrayfire.org/>`_ 等框架。與這些框架"
"相比，MLX 的一項重要差異是*統一記憶體模型*。MLX 的陣列位於共享記憶體中，對 "
"MLX 陣列的運算可以在任何支援的裝置類型上執行，而無需進行資料複製。目前支援的"
"裝置類型為 CPU 與 GPU。"

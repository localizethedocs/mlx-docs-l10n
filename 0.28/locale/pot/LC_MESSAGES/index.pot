# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Apple
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.28\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:32+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/index.rst:28
msgid "Install"
msgstr ""

#: ../../../src/index.rst:34
msgid "Usage"
msgstr ""

#: ../../../src/index.rst:50
msgid "Examples"
msgstr ""

#: ../../../src/index.rst:58
msgid "Python API Reference"
msgstr ""

#: ../../../src/index.rst:79
msgid "C++ API Reference"
msgstr ""

#: ../../../src/index.rst:85
msgid "Further Reading"
msgstr ""

#: ../../../src/index.rst:2
msgid "MLX"
msgstr ""

#: ../../../src/index.rst:4
msgid ""
"MLX is a NumPy-like array framework designed for efficient and flexible "
"machine learning on Apple silicon, brought to you by Apple machine learning "
"research."
msgstr ""

#: ../../../src/index.rst:7
msgid ""
"The Python API closely follows NumPy with a few exceptions. MLX also has a "
"fully featured C++ API which closely follows the Python API."
msgstr ""

#: ../../../src/index.rst:10
msgid "The main differences between MLX and NumPy are:"
msgstr ""

#: ../../../src/index.rst:12
msgid ""
"**Composable function transformations**: MLX has composable function "
"transformations for automatic differentiation, automatic vectorization, and "
"computation graph optimization."
msgstr ""

#: ../../../src/index.rst:15
msgid ""
"**Lazy computation**: Computations in MLX are lazy. Arrays are only "
"materialized when needed."
msgstr ""

#: ../../../src/index.rst:17
msgid ""
"**Multi-device**: Operations can run on any of the supported devices (CPU, "
"GPU, ...)"
msgstr ""

#: ../../../src/index.rst:20
msgid ""
"The design of MLX is inspired by frameworks like `PyTorch <https://pytorch."
"org/>`_, `Jax <https://github.com/google/jax>`_, and `ArrayFire <https://"
"arrayfire.org/>`_. A notable difference from these frameworks and MLX is the "
"*unified memory model*. Arrays in MLX live in shared memory. Operations on "
"MLX arrays can be performed on any of the supported device types without "
"performing data copies. Currently supported device types are the CPU and GPU."
msgstr ""

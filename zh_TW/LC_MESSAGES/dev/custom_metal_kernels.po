# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, MLX Contributors
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.21\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:17+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/dev/custom_metal_kernels.rst:4
msgid "Custom Metal Kernels"
msgstr "自訂 Metal 內核"

#: ../../../src/dev/custom_metal_kernels.rst:6
msgid ""
"MLX supports writing custom Metal kernels through the Python and C++ APIs."
msgstr "MLX 支援透過 Python 與 C++ API 撰寫自訂 Metal 內核。"

#: ../../../src/dev/custom_metal_kernels.rst:9
msgid "Simple Example"
msgstr "簡單範例"

#: ../../../src/dev/custom_metal_kernels.rst:11
msgid "Let's write a custom kernel that computes ``exp`` elementwise:"
msgstr "讓我們撰寫一個自訂內核，逐元素計算 ``exp``："

#: ../../../src/dev/custom_metal_kernels.rst:13
msgid ""
"def exp_elementwise(a: mx.array):\n"
"    source = \"\"\"\n"
"        uint elem = thread_position_in_grid.x;\n"
"        T tmp = inp[elem];\n"
"        out[elem] = metal::exp(tmp);\n"
"    \"\"\"\n"
"\n"
"    kernel = mx.fast.metal_kernel(\n"
"        name=\"myexp\",\n"
"        input_names=[\"inp\"],\n"
"        output_names=[\"out\"],\n"
"        source=source,\n"
"    )\n"
"    outputs = kernel(\n"
"        inputs=[a],\n"
"        template=[(\"T\", mx.float32)],\n"
"        grid=(a.size, 1, 1),\n"
"        threadgroup=(256, 1, 1),\n"
"        output_shapes=[a.shape],\n"
"        output_dtypes=[a.dtype],\n"
"    )\n"
"    return outputs[0]\n"
"\n"
"a = mx.random.normal(shape=(4, 16)).astype(mx.float16)\n"
"b = exp_elementwise(a)\n"
"assert mx.allclose(b, mx.exp(a))"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:43
msgid ""
"We are only required to pass the body of the Metal kernel in ``source``."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:45
msgid "The full function signature will be generated using:"
msgstr "完整的函式簽名會根據以下內容自動產生："

#: ../../../src/dev/custom_metal_kernels.rst:47
msgid "The shapes/dtypes of ``inputs``"
msgstr "``inputs`` 的形狀/資料型別"

#: ../../../src/dev/custom_metal_kernels.rst:48
msgid ""
"In the above, ``a`` is an ``mx.array`` of type ``mx.float16`` and we pass it "
"with the key ``inp`` so we will add ``const device float16_t* inp`` to the "
"signature. ``inp_shape``, ``inp_strides`` and ``inp_ndim`` are also added "
"for convenience if they are present in ``source``."
msgstr ""
"在上述例子中，``a`` 是型別為 ``mx.float16`` 的 ``mx.array``，並以鍵 ``inp`` "
"傳入，因此我們會在簽名中加入 ``const device float16_t* inp``。若 ``source`` "
"中出現 ``inp_shape``、``inp_strides`` 與 ``inp_ndim``，也會為了方便而一併加"
"入。"

#: ../../../src/dev/custom_metal_kernels.rst:52
msgid "The list of ``output_dtypes``"
msgstr "``output_dtypes`` 的列表"

#: ../../../src/dev/custom_metal_kernels.rst:53
msgid ""
"In the above, ``out`` is an ``mx.array`` of type ``mx.float16`` so we add "
"``device float16_t* out``."
msgstr ""
"在上述例子中，``out`` 是型別為 ``mx.float16`` 的 ``mx.array``，因此會加入 "
"``device float16_t* out``。"

#: ../../../src/dev/custom_metal_kernels.rst:55
msgid "Template parameters passed using ``template``"
msgstr "透過 ``template`` 傳入的範本參數"

#: ../../../src/dev/custom_metal_kernels.rst:56
msgid ""
"In the above, ``template=[(\"T\", mx.float32)]`` adds a template of "
"``template <typename T>`` to the function and instantiates the template with "
"``custom_kernel_myexp_float<float>``. Template parameters can be ``mx.core."
"Dtype``, ``int`` or ``bool``."
msgstr ""
"在上述例子中，``template=[(\"T\", mx.float32)]`` 會為函式加入 ``template "
"<typename T>``，並以 ``custom_kernel_myexp_float<float>`` 實例化此範本。範本"
"參數可以是 ``mx.core.Dtype``、``int`` 或 ``bool``。"

#: ../../../src/dev/custom_metal_kernels.rst:59
msgid ""
"Metal attributes used in ``source`` such as ``[[thread_position_in_grid]]``"
msgstr "``source`` 中使用的 Metal 屬性，例如 ``[[thread_position_in_grid]]``"

#: ../../../src/dev/custom_metal_kernels.rst:60
msgid ""
"These will be added as function arguments. All the attributes defined in "
"Table 5.8 of the `Metal Shading Language Specification <https://developer."
"apple.com/metal/Metal-Shading-Language-Specification.pdf>`_ are supported."
msgstr ""
"這些會被加入為函式參數。支援 `Metal Shading Language Specification <https://"
"developer.apple.com/metal/Metal-Shading-Language-Specification.pdf>`_ 表 5.8 "
"中定義的所有屬性。"

#: ../../../src/dev/custom_metal_kernels.rst:63
msgid ""
"Putting this all together, the generated function signature for ``myexp`` is "
"as follows:"
msgstr "綜合以上內容，``myexp`` 產生的函式簽名如下："

#: ../../../src/dev/custom_metal_kernels.rst:65
msgid ""
"template <typename T>\n"
"[[kernel]] void custom_kernel_myexp_float(\n"
"  const device float16_t* inp [[buffer(0)]],\n"
"  device float16_t* out [[buffer(1)]],\n"
"  uint3 thread_position_in_grid [[thread_position_in_grid]]) {\n"
"\n"
"        uint elem = thread_position_in_grid.x;\n"
"        T tmp = inp[elem];\n"
"        out[elem] = metal::exp(tmp);\n"
"\n"
"}\n"
"\n"
"template [[host_name(\"custom_kernel_myexp_float\")]] [[kernel]] "
"decltype(custom_kernel_myexp_float<float>) custom_kernel_myexp_float<float>;"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:81
msgid ""
"Note: ``grid`` and ``threadgroup`` are parameters to the Metal "
"`dispatchThreads <https://developer.apple.com/documentation/metal/"
"mtlcomputecommandencoder/2866532-dispatchthreads>`_ function. This means we "
"will launch ``mx.prod(grid)`` threads, subdivided into ``threadgroup`` size "
"threadgroups. For optimal performance, each thread group dimension should be "
"less than or equal to the corresponding grid dimension."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:85
msgid ""
"Passing ``verbose=True`` to ``mx.fast.metal_kernel.__call__`` will print the "
"generated code for debugging purposes."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:88
msgid "Using Shape/Strides"
msgstr "使用形狀/步幅"

#: ../../../src/dev/custom_metal_kernels.rst:90
msgid ""
"``mx.fast.metal_kernel`` supports an argument ``ensure_row_contiguous`` "
"which is ``True`` by default. This will copy the ``mx.array`` inputs if "
"needed before the kernel is launched to ensure that the memory layout is row "
"contiguous. Generally this makes writing the kernel easier, since we don't "
"have to worry about gaps or the ordering of the dims when indexing."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:95
msgid ""
"If we want to avoid this copy, ``metal_kernel`` automatically passes "
"``a_shape``, ``a_strides`` and ``a_ndim`` for each input array ``a`` if any "
"are present in ``source``. We can then use MLX's built in indexing utils to "
"fetch the right elements for each thread."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:99
msgid ""
"Let's convert ``myexp`` above to support arbitrarily strided arrays without "
"relying on a copy from ``ensure_row_contiguous``:"
msgstr ""
"讓我們把上面的 ``myexp`` 改成支援任意步幅的陣列，而不依賴 "
"``ensure_row_contiguous`` 的複製："

#: ../../../src/dev/custom_metal_kernels.rst:101
msgid ""
"def exp_elementwise(a: mx.array):\n"
"    source = \"\"\"\n"
"        uint elem = thread_position_in_grid.x;\n"
"        // Utils from `mlx/backend/metal/kernels/utils.h` are automatically "
"included\n"
"        uint loc = elem_to_loc(elem, inp_shape, inp_strides, inp_ndim);\n"
"        T tmp = inp[loc];\n"
"        // Output arrays are always row contiguous\n"
"        out[elem] = metal::exp(tmp);\n"
"    \"\"\"\n"
"\n"
"    kernel = mx.fast.metal_kernel(\n"
"        name=\"myexp_strided\",\n"
"        input_names=[\"inp\"],\n"
"        output_names=[\"out\"],\n"
"        source=source\n"
"    )\n"
"    outputs = kernel(\n"
"        inputs=[a],\n"
"        template=[(\"T\", mx.float32)],\n"
"        grid=(a.size, 1, 1),\n"
"        threadgroup=(256, 1, 1),\n"
"        output_shapes=[a.shape],\n"
"        output_dtypes=[a.dtype],\n"
"        ensure_row_contiguous=False,\n"
"    )\n"
"    return outputs[0]\n"
"\n"
"a = mx.random.normal(shape=(4, 16)).astype(mx.float16)\n"
"# make non-contiguous\n"
"a = a[::2]\n"
"b = exp_elementwise(a)\n"
"assert mx.allclose(b, mx.exp(a))"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:137
msgid "Complex Example"
msgstr "複雜範例"

#: ../../../src/dev/custom_metal_kernels.rst:139
msgid ""
"Let's implement a more complex example: ``grid_sample`` in ``\"bilinear\"`` "
"mode."
msgstr "讓我們實作更複雜的例子：``\"bilinear\"`` 模式的 ``grid_sample``。"

#: ../../../src/dev/custom_metal_kernels.rst:141
msgid "We'll start with the following MLX implementation using standard ops:"
msgstr "我們從使用標準運算的 MLX 實作開始："

#: ../../../src/dev/custom_metal_kernels.rst:143
msgid ""
"def grid_sample_ref(x, grid):\n"
"    N, H_in, W_in, _ = x.shape\n"
"    ix = ((grid[..., 0] + 1) * W_in - 1) / 2\n"
"    iy = ((grid[..., 1] + 1) * H_in - 1) / 2\n"
"\n"
"    ix_nw = mx.floor(ix).astype(mx.int32)\n"
"    iy_nw = mx.floor(iy).astype(mx.int32)\n"
"\n"
"    ix_ne = ix_nw + 1\n"
"    iy_ne = iy_nw\n"
"\n"
"    ix_sw = ix_nw\n"
"    iy_sw = iy_nw + 1\n"
"\n"
"    ix_se = ix_nw + 1\n"
"    iy_se = iy_nw + 1\n"
"\n"
"    nw = (ix_se - ix)    * (iy_se - iy)\n"
"    ne = (ix    - ix_sw) * (iy_sw - iy)\n"
"    sw = (ix_ne - ix)    * (iy    - iy_ne)\n"
"    se = (ix    - ix_nw) * (iy    - iy_nw)\n"
"\n"
"    I_nw = x[mx.arange(N)[:, None, None], iy_nw, ix_nw, :]\n"
"    I_ne = x[mx.arange(N)[:, None, None], iy_ne, ix_ne, :]\n"
"    I_sw = x[mx.arange(N)[:, None, None], iy_sw, ix_sw, :]\n"
"    I_se = x[mx.arange(N)[:, None, None], iy_se, ix_se, :]\n"
"\n"
"    mask_nw = (iy_nw >= 0) & (iy_nw <= H_in - 1) & (ix_nw >= 0) & (ix_nw <= "
"W_in - 1)\n"
"    mask_ne = (iy_ne >= 0) & (iy_ne <= H_in - 1) & (ix_ne >= 0) & (ix_ne <= "
"W_in - 1)\n"
"    mask_sw = (iy_sw >= 0) & (iy_sw <= H_in - 1) & (ix_sw >= 0) & (ix_sw <= "
"W_in - 1)\n"
"    mask_se = (iy_se >= 0) & (iy_se <= H_in - 1) & (ix_se >= 0) & (ix_se <= "
"W_in - 1)\n"
"\n"
"    I_nw *= mask_nw[..., None]\n"
"    I_ne *= mask_ne[..., None]\n"
"    I_sw *= mask_sw[..., None]\n"
"    I_se *= mask_se[..., None]\n"
"\n"
"    output = nw[..., None] * I_nw + ne[..., None] * I_ne + sw[..., None] * "
"I_sw + se[..., None] * I_se\n"
"\n"
"    return output"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:186
msgid ""
"Now let's use ``mx.custom_function`` together with ``mx.fast.metal_kernel`` "
"to write a fast GPU kernel for both the forward and backward passes."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:189
msgid "First we'll implement the forward pass as a fused kernel:"
msgstr "首先我們將正向傳播實作為融合內核："

#: ../../../src/dev/custom_metal_kernels.rst:191
msgid ""
"@mx.custom_function\n"
"def grid_sample(x, grid):\n"
"\n"
"    assert x.ndim == 4, \"`x` must be 4D.\"\n"
"    assert grid.ndim == 4, \"`grid` must be 4D.\"\n"
"\n"
"    B, _, _, C = x.shape\n"
"    _, gN, gM, D = grid.shape\n"
"    out_shape = (B, gN, gM, C)\n"
"\n"
"    assert D == 2, \"Last dim of `grid` must be size 2.\"\n"
"\n"
"    source = \"\"\"\n"
"        uint elem = thread_position_in_grid.x;\n"
"        int H = x_shape[1];\n"
"        int W = x_shape[2];\n"
"        int C = x_shape[3];\n"
"        int gH = grid_shape[1];\n"
"        int gW = grid_shape[2];\n"
"\n"
"        int w_stride = C;\n"
"        int h_stride = W * w_stride;\n"
"        int b_stride = H * h_stride;\n"
"\n"
"        uint grid_idx = elem / C * 2;\n"
"        float ix = ((grid[grid_idx] + 1) * W - 1) / 2;\n"
"        float iy = ((grid[grid_idx + 1] + 1) * H - 1) / 2;\n"
"\n"
"        int ix_nw = floor(ix);\n"
"        int iy_nw = floor(iy);\n"
"\n"
"        int ix_ne = ix_nw + 1;\n"
"        int iy_ne = iy_nw;\n"
"\n"
"        int ix_sw = ix_nw;\n"
"        int iy_sw = iy_nw + 1;\n"
"\n"
"        int ix_se = ix_nw + 1;\n"
"        int iy_se = iy_nw + 1;\n"
"\n"
"        T nw = (ix_se - ix)    * (iy_se - iy);\n"
"        T ne = (ix    - ix_sw) * (iy_sw - iy);\n"
"        T sw = (ix_ne - ix)    * (iy    - iy_ne);\n"
"        T se = (ix    - ix_nw) * (iy    - iy_nw);\n"
"\n"
"        int batch_idx = elem / C / gH / gW * b_stride;\n"
"        int channel_idx = elem % C;\n"
"        int base_idx = batch_idx + channel_idx;\n"
"\n"
"        T I_nw = x[base_idx + iy_nw * h_stride + ix_nw * w_stride];\n"
"        T I_ne = x[base_idx + iy_ne * h_stride + ix_ne * w_stride];\n"
"        T I_sw = x[base_idx + iy_sw * h_stride + ix_sw * w_stride];\n"
"        T I_se = x[base_idx + iy_se * h_stride + ix_se * w_stride];\n"
"\n"
"        I_nw = iy_nw >= 0 && iy_nw <= H - 1 && ix_nw >= 0 && ix_nw <= W - "
"1 ? I_nw : 0;\n"
"        I_ne = iy_ne >= 0 && iy_ne <= H - 1 && ix_ne >= 0 && ix_ne <= W - "
"1 ? I_ne : 0;\n"
"        I_sw = iy_sw >= 0 && iy_sw <= H - 1 && ix_sw >= 0 && ix_sw <= W - "
"1 ? I_sw : 0;\n"
"        I_se = iy_se >= 0 && iy_se <= H - 1 && ix_se >= 0 && ix_se <= W - "
"1 ? I_se : 0;\n"
"\n"
"        out[elem] = nw * I_nw + ne * I_ne + sw * I_sw + se * I_se;\n"
"    \"\"\"\n"
"    kernel = mx.fast.metal_kernel(\n"
"        name=\"grid_sample\",\n"
"        input_names=[\"x\", \"grid\"],\n"
"        output_names=[\"out\"],\n"
"        source=source,\n"
"    )\n"
"    outputs = kernel(\n"
"        inputs=[x, grid],\n"
"        template=[(\"T\", x.dtype)],\n"
"        output_shapes=[out_shape],\n"
"        output_dtypes=[x.dtype],\n"
"        grid=(np.prod(out_shape), 1, 1),\n"
"        threadgroup=(256, 1, 1),\n"
"    )\n"
"    return outputs[0]"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:270
msgid "For a reasonably sized input such as:"
msgstr "對於像是以下合理大小的輸入："

#: ../../../src/dev/custom_metal_kernels.rst:272
msgid ""
"x.shape = (8, 1024, 1024, 64)\n"
"grid.shape = (8, 256, 256, 2)"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:277
msgid "On an M1 Max, we see a big performance improvement:"
msgstr "在 M1 Max 上，我們看到顯著的效能提升："

#: ../../../src/dev/custom_metal_kernels.rst:279
msgid "``55.7ms -> 6.7ms => 8x speed up``"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:282
msgid "Grid Sample VJP"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:284
msgid ""
"Since we decorated ``grid_sample`` with ``mx.custom_function``, we can now "
"define its custom vjp transform so MLX can differentiate it."
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:287
msgid ""
"The backwards pass requires atomically updating ``x_grad``/``grid_grad`` and "
"so requires a few extra ``mx.fast.metal_kernel`` features:"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:290
msgid "``init_value=0``"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:291
msgid ""
"Initialize all of the kernel's outputs to this value before it runs. This "
"allows us to update only part of the output arrays with the kernel."
msgstr ""
"在內核執行前，將所有輸出初始化為此值。這讓我們可以只更新輸出陣列的一部分。"

#: ../../../src/dev/custom_metal_kernels.rst:293
msgid "``atomic_outputs=True``"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:294
msgid ""
"Designate all of the kernel outputs as ``atomic`` in the function signature. "
"This means we can use Metal's ``atomic`` features to simultaneously update "
"the ``x_grad`` and ``grid_grad`` arrays from multiple threadgroups. See "
"section 6.15 of the `Metal Shading Language Specification <https://developer."
"apple.com/metal/Metal-Shading-Language-Specification.pdf>`_ for more details."
msgstr ""
"在函式簽名中將所有內核輸出指定為 ``atomic``。這表示我們可以使用 Metal 的 "
"``atomic`` 功能，從多個執行緒群組同時更新 ``x_grad`` 和 ``grid_grad`` 陣列。"
"詳情請參見 `Metal Shading Language Specification <https://developer.apple."
"com/metal/Metal-Shading-Language-Specification.pdf>`_ 第 6.15 節。"

#: ../../../src/dev/custom_metal_kernels.rst:298
msgid "We can then implement the backwards pass as follows:"
msgstr "接著我們可以如下實作反向傳播："

#: ../../../src/dev/custom_metal_kernels.rst:300
msgid ""
"@grid_sample.vjp\n"
"def grid_sample_vjp(primals, cotangent, _):\n"
"    x, grid = primals\n"
"    B, _, _, C = x.shape\n"
"    _, gN, gM, D = grid.shape\n"
"\n"
"    assert D == 2, \"Last dim of `grid` must be size 2.\"\n"
"\n"
"    source = \"\"\"\n"
"        uint elem = thread_position_in_grid.x;\n"
"        int H = x_shape[1];\n"
"        int W = x_shape[2];\n"
"        int C = x_shape[3];\n"
"        // Pad C to the nearest larger simdgroup size multiple\n"
"        int C_padded = ceildiv(C, threads_per_simdgroup) * "
"threads_per_simdgroup;\n"
"\n"
"        int gH = grid_shape[1];\n"
"        int gW = grid_shape[2];\n"
"\n"
"        int w_stride = C;\n"
"        int h_stride = W * w_stride;\n"
"        int b_stride = H * h_stride;\n"
"\n"
"        uint grid_idx = elem / C_padded * 2;\n"
"        float ix = ((grid[grid_idx] + 1) * W - 1) / 2;\n"
"        float iy = ((grid[grid_idx + 1] + 1) * H - 1) / 2;\n"
"\n"
"        int ix_nw = floor(ix);\n"
"        int iy_nw = floor(iy);\n"
"\n"
"        int ix_ne = ix_nw + 1;\n"
"        int iy_ne = iy_nw;\n"
"\n"
"        int ix_sw = ix_nw;\n"
"        int iy_sw = iy_nw + 1;\n"
"\n"
"        int ix_se = ix_nw + 1;\n"
"        int iy_se = iy_nw + 1;\n"
"\n"
"        T nw = (ix_se - ix)    * (iy_se - iy);\n"
"        T ne = (ix    - ix_sw) * (iy_sw - iy);\n"
"        T sw = (ix_ne - ix)    * (iy    - iy_ne);\n"
"        T se = (ix    - ix_nw) * (iy    - iy_nw);\n"
"\n"
"        int batch_idx = elem / C_padded / gH / gW * b_stride;\n"
"        int channel_idx = elem % C_padded;\n"
"        int base_idx = batch_idx + channel_idx;\n"
"\n"
"        T gix = T(0);\n"
"        T giy = T(0);\n"
"        if (channel_idx < C) {\n"
"            int cot_index = elem / C_padded * C + channel_idx;\n"
"            T cot = cotangent[cot_index];\n"
"            if (iy_nw >= 0 && iy_nw <= H - 1 && ix_nw >= 0 && ix_nw <= W - "
"1) {\n"
"                int offset = base_idx + iy_nw * h_stride + ix_nw * "
"w_stride;\n"
"                atomic_fetch_add_explicit(&x_grad[offset], nw * cot, "
"memory_order_relaxed);\n"
"\n"
"                T I_nw = x[offset];\n"
"                gix -= I_nw * (iy_se - iy) * cot;\n"
"                giy -= I_nw * (ix_se - ix) * cot;\n"
"            }\n"
"            if (iy_ne >= 0 && iy_ne <= H - 1 && ix_ne >= 0 && ix_ne <= W - "
"1) {\n"
"                int offset = base_idx + iy_ne * h_stride + ix_ne * "
"w_stride;\n"
"                atomic_fetch_add_explicit(&x_grad[offset], ne * cot, "
"memory_order_relaxed);\n"
"\n"
"                T I_ne = x[offset];\n"
"                gix += I_ne * (iy_sw - iy) * cot;\n"
"                giy -= I_ne * (ix - ix_sw) * cot;\n"
"            }\n"
"            if (iy_sw >= 0 && iy_sw <= H - 1 && ix_sw >= 0 && ix_sw <= W - "
"1) {\n"
"                int offset = base_idx + iy_sw * h_stride + ix_sw * "
"w_stride;\n"
"                atomic_fetch_add_explicit(&x_grad[offset], sw * cot, "
"memory_order_relaxed);\n"
"\n"
"                T I_sw = x[offset];\n"
"                gix -= I_sw * (iy - iy_ne) * cot;\n"
"                giy += I_sw * (ix_ne - ix) * cot;\n"
"            }\n"
"            if (iy_se >= 0 && iy_se <= H - 1 && ix_se >= 0 && ix_se <= W - "
"1) {\n"
"                int offset = base_idx + iy_se * h_stride + ix_se * "
"w_stride;\n"
"                atomic_fetch_add_explicit(&x_grad[offset], se * cot, "
"memory_order_relaxed);\n"
"\n"
"                T I_se = x[offset];\n"
"                gix += I_se * (iy - iy_nw) * cot;\n"
"                giy += I_se * (ix - ix_nw) * cot;\n"
"            }\n"
"        }\n"
"\n"
"        T gix_mult = W / 2;\n"
"        T giy_mult = H / 2;\n"
"\n"
"        // Reduce across each simdgroup first.\n"
"        // This is much faster than relying purely on atomics.\n"
"        gix = simd_sum(gix);\n"
"        giy = simd_sum(giy);\n"
"\n"
"        if (thread_index_in_simdgroup == 0) {\n"
"            atomic_fetch_add_explicit(&grid_grad[grid_idx], gix * gix_mult, "
"memory_order_relaxed);\n"
"            atomic_fetch_add_explicit(&grid_grad[grid_idx + 1], giy * "
"giy_mult, memory_order_relaxed);\n"
"        }\n"
"    \"\"\"\n"
"    kernel = mx.fast.metal_kernel(\n"
"        name=\"grid_sample_grad\",\n"
"        input_names=[\"x\", \"grid\", \"cotangent\"],\n"
"        output_names=[\"x_grad\", \"grid_grad\"],\n"
"        source=source,\n"
"        atomic_outputs=True,\n"
"    )\n"
"    # pad the output channels to simd group size\n"
"    # so that our `simd_sum`s don't overlap.\n"
"    simdgroup_size = 32\n"
"    C_padded = (C + simdgroup_size - 1) // simdgroup_size * simdgroup_size\n"
"    grid_size = B * gN * gM * C_padded\n"
"    outputs = kernel(\n"
"        inputs=[x, grid, cotangent],\n"
"        template=[(\"T\", x.dtype)],\n"
"        output_shapes=[x.shape, grid.shape],\n"
"        output_dtypes=[x.dtype, x.dtype],\n"
"        grid=(grid_size, 1, 1),\n"
"        threadgroup=(256, 1, 1),\n"
"        init_value=0,\n"
"    )\n"
"    return outputs[0], outputs[1]"
msgstr ""

#: ../../../src/dev/custom_metal_kernels.rst:425
msgid "There's an even larger speed up for the vjp:"
msgstr "vjp 的加速幅度更大："

#: ../../../src/dev/custom_metal_kernels.rst:427
msgid "``676.4ms -> 16.7ms => 40x speed up``"
msgstr ""

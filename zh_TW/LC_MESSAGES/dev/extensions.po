# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, MLX Contributors
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.19\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:31+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/dev/extensions.rst:2
msgid "Custom Extensions in MLX"
msgstr "MLX 的自訂擴充"

#: ../../../src/dev/extensions.rst:4
msgid ""
"You can extend MLX with custom operations on the CPU or GPU. This guide "
"explains how to do that with a simple example."
msgstr ""
"你可以在 CPU 或 GPU 上用自訂運算擴充 MLX。本指南透過一個簡單範例說明如何做到"
"這點。"

#: ../../../src/dev/extensions.rst:8
msgid "Introducing the Example"
msgstr "範例介紹"

#: ../../../src/dev/extensions.rst:10
msgid ""
"Let's say you would like an operation that takes in two arrays, ``x`` and "
"``y``, scales them both by coefficients ``alpha`` and ``beta`` respectively, "
"and then adds them together to get the result ``z = alpha * x + beta * y``. "
"You can do that in MLX directly:"
msgstr ""
"假設你想要一個運算，輸入兩個陣列 ``x`` 和 ``y``，分別乘上係數 ``alpha`` 與 "
"``beta``，再相加得到結果 ``z = alpha * x + beta * y``。你可以直接在 MLX 中這"
"麼做："

#: ../../../src/dev/extensions.rst:15
msgid ""
"import mlx.core as mx\n"
"\n"
"def simple_axpby(x: mx.array, y: mx.array, alpha: float, beta: float) -> mx."
"array:\n"
"    return alpha * x + beta * y"
msgstr ""

#: ../../../src/dev/extensions.rst:22
msgid ""
"This function performs that operation while leaving the implementation and "
"function transformations to MLX."
msgstr "此函式執行該運算，同時將實作與函式轉換交給 MLX。"

#: ../../../src/dev/extensions.rst:25
msgid ""
"However you may need to customize the underlying implementation, perhaps to "
"make it faster or for custom differentiation. In this tutorial we will go "
"through adding custom extensions. It will cover:"
msgstr ""

#: ../../../src/dev/extensions.rst:29
msgid "The structure of the MLX library."
msgstr "MLX 程式庫的結構。"

#: ../../../src/dev/extensions.rst:30
msgid ""
"Implementing a CPU operation that redirects to Accelerate_ when appropriate."
msgstr ""

#: ../../../src/dev/extensions.rst:31
msgid "Implementing a GPU operation using metal."
msgstr "使用 Metal 實作 GPU 運算。"

#: ../../../src/dev/extensions.rst:32
msgid "Adding the ``vjp`` and ``jvp`` function transformation."
msgstr "加入 ``vjp`` 與 ``jvp`` 函式轉換。"

#: ../../../src/dev/extensions.rst:33
msgid "Building a custom extension and binding it to python."
msgstr "建置自訂擴充並綁定到 Python。"

#: ../../../src/dev/extensions.rst:36
msgid "Operations and Primitives"
msgstr "運算與原語"

#: ../../../src/dev/extensions.rst:38
msgid ""
"Operations in MLX build the computation graph. Primitives provide the rules "
"for evaluating and transforming the graph. Let's start by discussing "
"operations in more detail."
msgstr ""
"MLX 中的運算會建立計算圖。原語提供評估與轉換計算圖的規則。讓我們先更深入介紹"
"運算。"

#: ../../../src/dev/extensions.rst:43
msgid "Operations"
msgstr "運算"

#: ../../../src/dev/extensions.rst:45
msgid ""
"Operations are the front-end functions that operate on arrays. They are "
"defined in the C++ API (:ref:`cpp_ops`), and the Python API (:ref:`ops`) "
"binds them."
msgstr ""
"運算是對陣列操作的前端函式。它們定義於 C++ API（:ref:`cpp_ops`），並由 "
"Python API（:ref:`ops`）加以綁定。"

#: ../../../src/dev/extensions.rst:48
msgid ""
"We would like an operation, :meth:`axpby` that takes in two arrays ``x`` and "
"``y``, and two scalars, ``alpha`` and ``beta``. This is how to define it in "
"C++:"
msgstr ""

#: ../../../src/dev/extensions.rst:52
msgid ""
"/**\n"
"*  Scale and sum two vectors element-wise\n"
"*  z = alpha * x + beta * y\n"
"*\n"
"*  Follow numpy style broadcasting between x and y\n"
"*  Inputs are upcasted to floats if needed\n"
"**/\n"
"array axpby(\n"
"    const array& x, // Input array x\n"
"    const array& y, // Input array y\n"
"    const float alpha, // Scaling factor for x\n"
"    const float beta, // Scaling factor for y\n"
"    StreamOrDevice s = {} // Stream on which to schedule the operation\n"
");"
msgstr ""

#: ../../../src/dev/extensions.rst:69
msgid "The simplest way to this operation is in terms of existing operations:"
msgstr ""

#: ../../../src/dev/extensions.rst:71
msgid ""
"array axpby(\n"
"    const array& x, // Input array x\n"
"    const array& y, // Input array y\n"
"    const float alpha, // Scaling factor for x\n"
"    const float beta, // Scaling factor for y\n"
"    StreamOrDevice s /* = {} */ // Stream on which to schedule the "
"operation\n"
") {\n"
"    // Scale x and y on the provided stream\n"
"    auto ax = multiply(array(alpha), x, s);\n"
"    auto by = multiply(array(beta), y, s);\n"
"\n"
"    // Add and return\n"
"    return add(ax, by, s);\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:88
msgid ""
"The operations themselves do not contain the implementations that act on the "
"data, nor do they contain the rules of transformations. Rather, they are an "
"easy to use interface that use :class:`Primitive` building blocks."
msgstr ""
"運算本身不包含作用於資料的實作，也不包含轉換規則。相反地，它們是易用的介面，"
"以 :class:`Primitive` 為建構基礎。"

#: ../../../src/dev/extensions.rst:93
msgid "Primitives"
msgstr "原語"

#: ../../../src/dev/extensions.rst:95
msgid ""
"A :class:`Primitive` is part of the computation graph of an :class:`array`. "
"It defines how to create outputs arrays given a input arrays. Further, a :"
"class:`Primitive` has methods to run on the CPU or GPU and for function "
"transformations such as ``vjp`` and ``jvp``.  Lets go back to our example to "
"be more concrete:"
msgstr ""

#: ../../../src/dev/extensions.rst:101
msgid ""
"class Axpby : public Primitive {\n"
"  public:\n"
"    explicit Axpby(Stream stream, float alpha, float beta)\n"
"        : Primitive(stream), alpha_(alpha), beta_(beta){};\n"
"\n"
"    /**\n"
"    * A primitive must know how to evaluate itself on the CPU/GPU\n"
"    * for the given inputs and populate the output array.\n"
"    *\n"
"    * To avoid unnecessary allocations, the evaluation function\n"
"    * is responsible for allocating space for the array.\n"
"    */\n"
"    void eval_cpu(\n"
"        const std::vector<array>& inputs,\n"
"        std::vector<array>& outputs) override;\n"
"    void eval_gpu(\n"
"        const std::vector<array>& inputs,\n"
"        std::vector<array>& outputs) override;\n"
"\n"
"    /** The Jacobian-vector product. */\n"
"    std::vector<array> jvp(\n"
"        const std::vector<array>& primals,\n"
"        const std::vector<array>& tangents,\n"
"        const std::vector<int>& argnums) override;\n"
"\n"
"    /** The vector-Jacobian product. */\n"
"    std::vector<array> vjp(\n"
"        const std::vector<array>& primals,\n"
"        const array& cotan,\n"
"        const std::vector<int>& argnums,\n"
"        const std::vector<array>& outputs) override;\n"
"\n"
"    /**\n"
"    * The primitive must know how to vectorize itself across\n"
"    * the given axes. The output is a pair containing the array\n"
"    * representing the vectorized computation and the axis which\n"
"    * corresponds to the output vectorized dimension.\n"
"    */\n"
"    virtual std::pair<std::vector<array>, std::vector<int>> vmap(\n"
"        const std::vector<array>& inputs,\n"
"        const std::vector<int>& axes) override;\n"
"\n"
"    /** Print the primitive. */\n"
"    void print(std::ostream& os) override {\n"
"        os << \"Axpby\";\n"
"    }\n"
"\n"
"    /** Equivalence check **/\n"
"    bool is_equivalent(const Primitive& other) const override;\n"
"\n"
"  private:\n"
"    float alpha_;\n"
"    float beta_;\n"
"\n"
"    /** Fall back implementation for evaluation on CPU */\n"
"    void eval(const std::vector<array>& inputs, array& out);\n"
"};"
msgstr ""

#: ../../../src/dev/extensions.rst:161
msgid ""
"The :class:`Axpby` class derives from the base :class:`Primitive` class. "
"The :class:`Axpby` treats ``alpha`` and ``beta`` as parameters. It then "
"provides implementations of how the output array is produced given the "
"inputs through :meth:`Axpby::eval_cpu` and :meth:`Axpby::eval_gpu`. It also "
"provides rules of transformations in :meth:`Axpby::jvp`, :meth:`Axpby::vjp`, "
"and :meth:`Axpby::vmap`."
msgstr ""
":class:`Axpby` 類別衍生自基礎 :class:`Primitive` 類別。:class:`Axpby` 將 "
"``alpha`` 與 ``beta`` 視為參數，並透過 :meth:`Axpby::eval_cpu` 與 :meth:"
"`Axpby::eval_gpu` 提供在給定輸入時產生輸出陣列的實作。同時也在 :meth:`Axpby::"
"jvp`、:meth:`Axpby::vjp` 與 :meth:`Axpby::vmap` 中提供轉換規則。"

#: ../../../src/dev/extensions.rst:169
msgid "Using the Primitive"
msgstr "使用原語"

#: ../../../src/dev/extensions.rst:171
msgid ""
"Operations can use this :class:`Primitive` to add a new :class:`array` to "
"the computation graph. An :class:`array` can be constructed by providing its "
"data type, shape, the :class:`Primitive` that computes it, and the :class:"
"`array` inputs that are passed to the primitive."
msgstr ""
"運算可以使用此 :class:`Primitive` 在計算圖中新增一個 :class:`array`。建立:"
"class:`array` 時可提供其資料型別、形狀、負責計算它的 :class:`Primitive`，以及"
"傳給該原語的 :class:`array` 輸入。"

#: ../../../src/dev/extensions.rst:176
msgid ""
"Let's reimplement our operation now in terms of our :class:`Axpby` primitive."
msgstr "讓我們以 :class:`Axpby` 原語重新實作該運算。"

#: ../../../src/dev/extensions.rst:178
msgid ""
"array axpby(\n"
"    const array& x, // Input array x\n"
"    const array& y, // Input array y\n"
"    const float alpha, // Scaling factor for x\n"
"    const float beta, // Scaling factor for y\n"
"    StreamOrDevice s /* = {} */ // Stream on which to schedule the "
"operation\n"
") {\n"
"    // Promote dtypes between x and y as needed\n"
"    auto promoted_dtype = promote_types(x.dtype(), y.dtype());\n"
"\n"
"    // Upcast to float32 for non-floating point inputs x and y\n"
"    auto out_dtype = is_floating_point(promoted_dtype)\n"
"        ? promoted_dtype\n"
"        : promote_types(promoted_dtype, float32);\n"
"\n"
"    // Cast x and y up to the determined dtype (on the same stream s)\n"
"    auto x_casted = astype(x, out_dtype, s);\n"
"    auto y_casted = astype(y, out_dtype, s);\n"
"\n"
"    // Broadcast the shapes of x and y (on the same stream s)\n"
"    auto broadcasted_inputs = broadcast_arrays({x_casted, y_casted}, s);\n"
"    auto out_shape = broadcasted_inputs[0].shape();\n"
"\n"
"    // Construct the array as the output of the Axpby primitive\n"
"    // with the broadcasted and upcasted arrays as inputs\n"
"    return array(\n"
"        /* const std::vector<int>& shape = */ out_shape,\n"
"        /* Dtype dtype = */ out_dtype,\n"
"        /* std::unique_ptr<Primitive> primitive = */\n"
"        std::make_shared<Axpby>(to_stream(s), alpha, beta),\n"
"        /* const std::vector<array>& inputs = */ broadcasted_inputs);\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:214
msgid "This operation now handles the following:"
msgstr "此運算現在會處理以下事項："

#: ../../../src/dev/extensions.rst:216
msgid "Upcast inputs and resolve the output data type."
msgstr "將輸入升型並決定輸出資料型別。"

#: ../../../src/dev/extensions.rst:217
msgid "Broadcast the inputs and resolve the output shape."
msgstr "廣播輸入並決定輸出形狀。"

#: ../../../src/dev/extensions.rst:218
msgid ""
"Construct the primitive :class:`Axpby` using the given stream, ``alpha``, "
"and ``beta``."
msgstr "使用給定的 stream、``alpha`` 與 ``beta`` 建立 :class:`Axpby` 原語。"

#: ../../../src/dev/extensions.rst:219
msgid "Construct the output :class:`array` using the primitive and the inputs."
msgstr "使用原語與輸入建立輸出 :class:`array`。"

#: ../../../src/dev/extensions.rst:222
msgid "Implementing the Primitive"
msgstr "實作原語"

#: ../../../src/dev/extensions.rst:224
msgid ""
"No computation happens when we call the operation alone. The operation only "
"builds the computation graph. When we evaluate the output array, MLX "
"schedules the execution of the computation graph, and calls :meth:`Axpby::"
"eval_cpu` or :meth:`Axpby::eval_gpu` depending on the stream/device "
"specified by the user."
msgstr ""
"單獨呼叫該運算時不會進行計算。運算只會建立計算圖。當我們對輸出陣列求值時，"
"MLX 會排程計算圖的執行，並根據使用者指定的 stream/裝置呼叫 :meth:`Axpby::"
"eval_cpu` 或 :meth:`Axpby::eval_gpu`。"

#: ../../../src/dev/extensions.rst:230
msgid ""
"When :meth:`Primitive::eval_cpu` or :meth:`Primitive::eval_gpu` are called, "
"no memory has been allocated for the output array. It falls on the "
"implementation of these functions to allocate memory as needed."
msgstr ""
"當呼叫 :meth:`Primitive::eval_cpu` 或 :meth:`Primitive::eval_gpu` 時，輸出陣"
"列尚未分配記憶體。因此需要由這些函式的實作來視需求配置記憶體。"

#: ../../../src/dev/extensions.rst:235
msgid "Implementing the CPU Back-end"
msgstr "實作 CPU 後端"

#: ../../../src/dev/extensions.rst:237
msgid ""
"Let's start by implementing a naive and generic version of :meth:`Axpby::"
"eval_cpu`. We declared this as a private member function of :class:`Axpby` "
"earlier called :meth:`Axpby::eval`."
msgstr ""

#: ../../../src/dev/extensions.rst:241
msgid ""
"Our naive method will go over each element of the output array, find the "
"corresponding input elements of ``x`` and ``y`` and perform the operation "
"point-wise. This is captured in the templated function :meth:`axpby_impl`."
msgstr ""

#: ../../../src/dev/extensions.rst:245
msgid ""
"template <typename T>\n"
"void axpby_impl(\n"
"        const array& x,\n"
"        const array& y,\n"
"        array& out,\n"
"        float alpha_,\n"
"        float beta_) {\n"
"    // We only allocate memory when we are ready to fill the output\n"
"    // malloc_or_wait synchronously allocates available memory\n"
"    // There may be a wait executed here if the allocation is requested\n"
"    // under memory-pressured conditions\n"
"    out.set_data(allocator::malloc_or_wait(out.nbytes()));\n"
"\n"
"    // Collect input and output data pointers\n"
"    const T* x_ptr = x.data<T>();\n"
"    const T* y_ptr = y.data<T>();\n"
"    T* out_ptr = out.data<T>();\n"
"\n"
"    // Cast alpha and beta to the relevant types\n"
"    T alpha = static_cast<T>(alpha_);\n"
"    T beta = static_cast<T>(beta_);\n"
"\n"
"    // Do the element-wise operation for each output\n"
"    for (size_t out_idx = 0; out_idx < out.size(); out_idx++) {\n"
"        // Map linear indices to offsets in x and y\n"
"        auto x_offset = elem_to_loc(out_idx, x.shape(), x.strides());\n"
"        auto y_offset = elem_to_loc(out_idx, y.shape(), y.strides());\n"
"\n"
"        // We allocate the output to be contiguous and regularly strided\n"
"        // (defaults to row major) and hence it doesn't need additional "
"mapping\n"
"        out_ptr[out_idx] = alpha * x_ptr[x_offset] + beta * "
"y_ptr[y_offset];\n"
"    }\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:281
msgid ""
"Our implementation should work for all incoming floating point arrays. "
"Accordingly, we add dispatches for ``float32``, ``float16``, ``bfloat16`` "
"and ``complex64``. We throw an error if we encounter an unexpected type."
msgstr ""
"我們的實作應適用於所有輸入的浮點陣列。因此我們為 ``float32``、``float16``、"
"``bfloat16`` 與 ``complex64`` 加入分派。若遇到非預期型別就會拋出錯誤。"

#: ../../../src/dev/extensions.rst:285
msgid ""
"/** Fall back implementation for evaluation on CPU */\n"
"void Axpby::eval(\n"
"  const std::vector<array>& inputs,\n"
"  const std::vector<array>& outputs) {\n"
"    auto& x = inputs[0];\n"
"    auto& y = inputs[1];\n"
"    auto& out = outputs[0];\n"
"\n"
"    // Dispatch to the correct dtype\n"
"    if (out.dtype() == float32) {\n"
"        return axpby_impl<float>(x, y, out, alpha_, beta_);\n"
"    } else if (out.dtype() == float16) {\n"
"        return axpby_impl<float16_t>(x, y, out, alpha_, beta_);\n"
"    } else if (out.dtype() == bfloat16) {\n"
"        return axpby_impl<bfloat16_t>(x, y, out, alpha_, beta_);\n"
"    } else if (out.dtype() == complex64) {\n"
"        return axpby_impl<complex64_t>(x, y, out, alpha_, beta_);\n"
"    } else {\n"
"        throw std::runtime_error(\n"
"            \"[Axpby] Only supports floating point types.\");\n"
"    }\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:310
msgid ""
"This is good as a fallback implementation. We can use the ``axpby`` routine "
"provided by the Accelerate_ framework for a faster implementation in certain "
"cases:"
msgstr ""

#: ../../../src/dev/extensions.rst:314
msgid ""
"Accelerate does not provide implementations of ``axpby`` for half precision "
"floats. We can only use it for ``float32`` types."
msgstr ""

#: ../../../src/dev/extensions.rst:316
msgid ""
"Accelerate assumes the inputs ``x`` and ``y`` are contiguous and all "
"elements have fixed strides between them. We only direct to Accelerate if "
"both ``x`` and ``y`` are row contiguous or column contiguous."
msgstr ""

#: ../../../src/dev/extensions.rst:319
msgid ""
"Accelerate performs the routine ``Y = (alpha * X) + (beta * Y)`` in-place. "
"MLX expects to write the output to a new array. We must copy the elements of "
"``y`` into the output and use that as an input to ``axpby``."
msgstr ""

#: ../../../src/dev/extensions.rst:323
msgid ""
"Let's write an implementation that uses Accelerate in the right conditions. "
"It allocates data for the output, copies ``y`` into it, and then calls the :"
"func:`catlas_saxpby` from accelerate."
msgstr ""

#: ../../../src/dev/extensions.rst:327
msgid ""
"template <typename T>\n"
"void axpby_impl_accelerate(\n"
"        const array& x,\n"
"        const array& y,\n"
"        array& out,\n"
"        float alpha_,\n"
"        float beta_) {\n"
"    // Accelerate library provides catlas_saxpby which does\n"
"    // Y = (alpha * X) + (beta * Y) in place\n"
"    // To use it, we first copy the data in y over to the output array\n"
"    out.set_data(allocator::malloc_or_wait(out.nbytes()));\n"
"\n"
"    // We then copy over the elements using the contiguous vector "
"specialization\n"
"    copy_inplace(y, out, CopyType::Vector);\n"
"\n"
"    // Get x and y pointers for catlas_saxpby\n"
"    const T* x_ptr = x.data<T>();\n"
"    T* y_ptr = out.data<T>();\n"
"\n"
"    T alpha = static_cast<T>(alpha_);\n"
"    T beta = static_cast<T>(beta_);\n"
"\n"
"    // Call the inplace accelerate operator\n"
"    catlas_saxpby(\n"
"        /* N = */ out.size(),\n"
"        /* ALPHA = */ alpha,\n"
"        /* X = */ x_ptr,\n"
"        /* INCX = */ 1,\n"
"        /* BETA = */ beta,\n"
"        /* Y = */ y_ptr,\n"
"        /* INCY = */ 1);\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:362
msgid ""
"For inputs that do not fit the criteria for accelerate, we fall back to :"
"meth:`Axpby::eval`. With this in mind, let's finish our :meth:`Axpby::"
"eval_cpu`."
msgstr ""

#: ../../../src/dev/extensions.rst:366
msgid ""
"/** Evaluate primitive on CPU using accelerate specializations */\n"
"void Axpby::eval_cpu(\n"
"  const std::vector<array>& inputs,\n"
"  const std::vector<array>& outputs) {\n"
"    assert(inputs.size() == 2);\n"
"    auto& x = inputs[0];\n"
"    auto& y = inputs[1];\n"
"    auto& out = outputs[0];\n"
"\n"
"    // Accelerate specialization for contiguous single precision float "
"arrays\n"
"    if (out.dtype() == float32 &&\n"
"        ((x.flags().row_contiguous && y.flags().row_contiguous) ||\n"
"        (x.flags().col_contiguous && y.flags().col_contiguous))) {\n"
"        axpby_impl_accelerate<float>(x, y, out, alpha_, beta_);\n"
"        return;\n"
"    }\n"
"\n"
"    // Fall back to common back-end if specializations are not available\n"
"    eval(inputs, outputs);\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:389
msgid ""
"Just this much is enough to run the operation :meth:`axpby` on a CPU stream! "
"If you do not plan on running the operation on the GPU or using transforms "
"on computation graphs that contain :class:`Axpby`, you can stop implementing "
"the primitive here and enjoy the speed-ups you get from the Accelerate "
"library."
msgstr ""

#: ../../../src/dev/extensions.rst:395
msgid "Implementing the GPU Back-end"
msgstr "實作 GPU 後端"

#: ../../../src/dev/extensions.rst:397
msgid ""
"Apple silicon devices address their GPUs using the Metal_ shading language, "
"and GPU kernels in MLX are written using Metal."
msgstr ""
"Apple silicon 裝置透過 Metal_ 著色語言存取 GPU，而 MLX 的 GPU 內核則使用 "
"Metal 撰寫。"

#: ../../../src/dev/extensions.rst:402
msgid "Here are some helpful resources if you are new to Metal:"
msgstr "如果你剛接觸 Metal，以下資源會很有幫助："

#: ../../../src/dev/extensions.rst:404
msgid "A walkthrough of the metal compute pipeline: `Metal Example`_"
msgstr "Metal 計算管線導覽：`Metal Example`_"

#: ../../../src/dev/extensions.rst:405
msgid "Documentation for metal shading language: `Metal Specification`_"
msgstr "Metal 著色語言文件：`Metal Specification`_"

#: ../../../src/dev/extensions.rst:406
msgid "Using metal from C++: `Metal-cpp`_"
msgstr "從 C++ 使用 Metal：`Metal-cpp`_"

#: ../../../src/dev/extensions.rst:408
msgid ""
"Let's keep the GPU kernel simple. We will launch exactly as many threads as "
"there are elements in the output. Each thread will pick the element it needs "
"from ``x`` and ``y``, do the point-wise operation, and update its assigned "
"element in the output."
msgstr ""
"讓 GPU 內核保持簡單。我們會啟動與輸出元素數量相同的執行緒。每個執行緒會從 "
"``x`` 與 ``y`` 取出需要的元素，進行逐點運算，並更新其負責的輸出元素。"

#: ../../../src/dev/extensions.rst:413
msgid ""
"template <typename T>\n"
"[[kernel]] void axpby_general(\n"
"        device const T* x [[buffer(0)]],\n"
"        device const T* y [[buffer(1)]],\n"
"        device T* out [[buffer(2)]],\n"
"        constant const float& alpha [[buffer(3)]],\n"
"        constant const float& beta [[buffer(4)]],\n"
"        constant const int* shape [[buffer(5)]],\n"
"        constant const size_t* x_strides [[buffer(6)]],\n"
"        constant const size_t* y_strides [[buffer(7)]],\n"
"        constant const int& ndim [[buffer(8)]],\n"
"        uint index [[thread_position_in_grid]]) {\n"
"    // Convert linear indices to offsets in array\n"
"    auto x_offset = elem_to_loc(index, shape, x_strides, ndim);\n"
"    auto y_offset = elem_to_loc(index, shape, y_strides, ndim);\n"
"\n"
"    // Do the operation and update the output\n"
"    out[index] =\n"
"        static_cast<T>(alpha) * x[x_offset] + static_cast<T>(beta) * "
"y[y_offset];\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:436
msgid ""
"We then need to instantiate this template for all floating point types and "
"give each instantiation a unique host name so we can identify it."
msgstr ""
"接著需要為所有浮點型別實例化此範本，並為每個實例指定唯一的 host name 以便識"
"別。"

#: ../../../src/dev/extensions.rst:439
msgid ""
"#define instantiate_axpby(type_name, type)              \\\n"
"    template [[host_name(\"axpby_general_\" #type_name)]] \\\n"
"    [[kernel]] void axpby_general<type>(                \\\n"
"        device const type* x [[buffer(0)]],             \\\n"
"        device const type* y [[buffer(1)]],             \\\n"
"        device type* out [[buffer(2)]],                 \\\n"
"        constant const float& alpha [[buffer(3)]],      \\\n"
"        constant const float& beta [[buffer(4)]],       \\\n"
"        constant const int* shape [[buffer(5)]],        \\\n"
"        constant const size_t* x_strides [[buffer(6)]], \\\n"
"        constant const size_t* y_strides [[buffer(7)]], \\\n"
"        constant const int& ndim [[buffer(8)]],         \\\n"
"        uint index [[thread_position_in_grid]]);\n"
"\n"
"instantiate_axpby(float32, float);\n"
"instantiate_axpby(float16, half);\n"
"instantiate_axpby(bfloat16, bfloat16_t);\n"
"instantiate_axpby(complex64, complex64_t);"
msgstr ""

#: ../../../src/dev/extensions.rst:460
msgid ""
"The logic to determine the kernel, set the inputs, resolve the grid "
"dimensions, and dispatch to the GPU are contained in :meth:`Axpby::eval_gpu` "
"as shown below."
msgstr ""
"用於決定內核、設定輸入、解析網格維度與分派到 GPU 的邏輯，都在 :meth:`Axpby::"
"eval_gpu` 中，如下所示。"

#: ../../../src/dev/extensions.rst:464
msgid ""
"/** Evaluate primitive on GPU */\n"
"void Axpby::eval_gpu(\n"
"  const std::vector<array>& inputs,\n"
"  std::vector<array>& outputs) {\n"
"    // Prepare inputs\n"
"    assert(inputs.size() == 2);\n"
"    auto& x = inputs[0];\n"
"    auto& y = inputs[1];\n"
"    auto& out = outputs[0];\n"
"\n"
"    // Each primitive carries the stream it should execute on\n"
"    // and each stream carries its device identifiers\n"
"    auto& s = stream();\n"
"    // We get the needed metal device using the stream\n"
"    auto& d = metal::device(s.device);\n"
"\n"
"    // Allocate output memory\n"
"    out.set_data(allocator::malloc_or_wait(out.nbytes()));\n"
"\n"
"    // Resolve name of kernel\n"
"    std::ostringstream kname;\n"
"    kname << \"axpby_\" << \"general_\" << type_to_name(out);\n"
"\n"
"    // Make sure the metal library is available\n"
"    d.register_library(\"mlx_ext\");\n"
"\n"
"    // Make a kernel from this metal library\n"
"    auto kernel = d.get_kernel(kname.str(), \"mlx_ext\");\n"
"\n"
"    // Prepare to encode kernel\n"
"    auto& compute_encoder = d.get_command_encoder(s.index);\n"
"    compute_encoder->setComputePipelineState(kernel);\n"
"\n"
"    // Kernel parameters are registered with buffer indices corresponding "
"to\n"
"    // those in the kernel declaration at axpby.metal\n"
"    int ndim = out.ndim();\n"
"    size_t nelem = out.size();\n"
"\n"
"    // Encode input arrays to kernel\n"
"    compute_encoder.set_input_array(x, 0);\n"
"    compute_encoder.set_input_array(y, 1);\n"
"\n"
"    // Encode output arrays to kernel\n"
"    compute_encoder.set_output_array(out, 2);\n"
"\n"
"    // Encode alpha and beta\n"
"    compute_encoder->setBytes(&alpha_, sizeof(float), 3);\n"
"    compute_encoder->setBytes(&beta_, sizeof(float), 4);\n"
"\n"
"    // Encode shape, strides and ndim\n"
"    compute_encoder->setBytes(x.shape().data(), ndim * sizeof(int), 5);\n"
"    compute_encoder->setBytes(x.strides().data(), ndim * sizeof(size_t), "
"6);\n"
"    compute_encoder->setBytes(y.strides().data(), ndim * sizeof(size_t), "
"7);\n"
"    compute_encoder->setBytes(&ndim, sizeof(int), 8);\n"
"\n"
"    // We launch 1 thread for each input and make sure that the number of\n"
"    // threads in any given threadgroup is not higher than the max allowed\n"
"    size_t tgp_size = std::min(nelem, kernel-"
">maxTotalThreadsPerThreadgroup());\n"
"\n"
"    // Fix the 3D size of each threadgroup (in terms of threads)\n"
"    MTL::Size group_dims = MTL::Size(tgp_size, 1, 1);\n"
"\n"
"    // Fix the 3D size of the launch grid (in terms of threads)\n"
"    MTL::Size grid_dims = MTL::Size(nelem, 1, 1);\n"
"\n"
"    // Launch the grid with the given number of threads divided among\n"
"    // the given threadgroups\n"
"    compute_encoder.dispatchThreads(grid_dims, group_dims);\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:536
msgid ""
"We can now call the :meth:`axpby` operation on both the CPU and the GPU!"
msgstr "現在我們可以在 CPU 和 GPU 上呼叫 :meth:`axpby` 運算了！"

#: ../../../src/dev/extensions.rst:538
msgid ""
"A few things to note about MLX and Metal before moving on. MLX keeps track "
"of the active ``command_buffer`` and the ``MTLCommandBuffer`` to which it is "
"associated. We rely on :meth:`d.get_command_encoder` to give us the active "
"metal compute command encoder instead of building a new one and calling :"
"meth:`compute_encoder->end_encoding` at the end. MLX adds kernels (compute "
"pipelines) to the active command buffer until some specified limit is hit or "
"the command buffer needs to be flushed for synchronization."
msgstr ""
"在繼續之前，先留意關於 MLX 與 Metal 的幾點：MLX 會追蹤目前的 "
"``command_buffer`` 與其對應的 ``MTLCommandBuffer``。我們會依賴 :meth:`d."
"get_command_encoder` 取得目前使用中的 Metal 計算命令編碼器，而不是自行建立新"
"的編碼器並在最後呼叫 :meth:`compute_encoder->end_encoding`。MLX 會持續將內核"
"（計算管線）加入目前的命令緩衝區，直到達到指定上限或命令緩衝區需要為同步而清"
"空。"

#: ../../../src/dev/extensions.rst:547
msgid "Primitive Transforms"
msgstr "原語轉換"

#: ../../../src/dev/extensions.rst:549
msgid ""
"Next, let's add implementations for transformations in a :class:`Primitive`. "
"These transformations can be built on top of other operations, including the "
"one we just defined:"
msgstr ""
"接下來，我們將為 :class:`Primitive` 的轉換加入實作。這些轉換可以建構在其他運"
"算之上，包括我們剛剛定義的運算："

#: ../../../src/dev/extensions.rst:553
msgid ""
"/** The Jacobian-vector product. */\n"
"std::vector<array> Axpby::jvp(\n"
"        const std::vector<array>& primals,\n"
"        const std::vector<array>& tangents,\n"
"        const std::vector<int>& argnums) {\n"
"    // Forward mode diff that pushes along the tangents\n"
"    // The jvp transform on the primitive can built with ops\n"
"    // that are scheduled on the same stream as the primitive\n"
"\n"
"    // If argnums = {0}, we only push along x in which case the\n"
"    // jvp is just the tangent scaled by alpha\n"
"    // Similarly, if argnums = {1}, the jvp is just the tangent\n"
"    // scaled by beta\n"
"    if (argnums.size() > 1) {\n"
"        auto scale = argnums[0] == 0 ? alpha_ : beta_;\n"
"        auto scale_arr = array(scale, tangents[0].dtype());\n"
"        return {multiply(scale_arr, tangents[0], stream())};\n"
"    }\n"
"    // If, argnums = {0, 1}, we take contributions from both\n"
"    // which gives us jvp = tangent_x * alpha + tangent_y * beta\n"
"    else {\n"
"        return {axpby(tangents[0], tangents[1], alpha_, beta_, stream())};\n"
"    }\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:580
msgid ""
"/** The vector-Jacobian product. */\n"
"std::vector<array> Axpby::vjp(\n"
"        const std::vector<array>& primals,\n"
"        const std::vector<array>& cotangents,\n"
"        const std::vector<int>& argnums,\n"
"        const std::vector<int>& /* unused */) {\n"
"    // Reverse mode diff\n"
"    std::vector<array> vjps;\n"
"    for (auto arg : argnums) {\n"
"        auto scale = arg == 0 ? alpha_ : beta_;\n"
"        auto scale_arr = array(scale, cotangents[0].dtype());\n"
"        vjps.push_back(multiply(scale_arr, cotangents[0], stream()));\n"
"    }\n"
"    return vjps;\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:598
msgid ""
"Note, a transformation does not need to be fully defined to start using the :"
"class:`Primitive`."
msgstr "注意，轉換不需要完整定義即可開始使用 :class:`Primitive`。"

#: ../../../src/dev/extensions.rst:601
msgid ""
"/** Vectorize primitive along given axis */\n"
"std::pair<std::vector<array>, std::vector<int>> Axpby::vmap(\n"
"        const std::vector<array>& inputs,\n"
"        const std::vector<int>& axes) {\n"
"    throw std::runtime_error(\"[Axpby] vmap not implemented.\");\n"
"}"
msgstr ""

#: ../../../src/dev/extensions.rst:611
msgid "Building and Binding"
msgstr "建置與綁定"

#: ../../../src/dev/extensions.rst:613
msgid "Let's look at the overall directory structure first."
msgstr "先看看整體目錄結構。"

#: ../../../src/dev/extensions.rst:615 ../../../src/dev/extensions.rst:794
msgid "extensions"
msgstr ""

#: ../../../src/dev/extensions.rst:616
msgid "├── axpby"
msgstr ""

#: ../../../src/dev/extensions.rst:617
msgid "│   ├── axpby.cpp"
msgstr ""

#: ../../../src/dev/extensions.rst:618
msgid "│   ├── axpby.h"
msgstr ""

#: ../../../src/dev/extensions.rst:619
msgid "│   └── axpby.metal"
msgstr ""

#: ../../../src/dev/extensions.rst:620 ../../../src/dev/extensions.rst:795
msgid "├── mlx_sample_extensions"
msgstr ""

#: ../../../src/dev/extensions.rst:621
msgid "│   └── __init__.py"
msgstr ""

#: ../../../src/dev/extensions.rst:622
msgid "├── bindings.cpp"
msgstr ""

#: ../../../src/dev/extensions.rst:623
msgid "├── CMakeLists.txt"
msgstr ""

#: ../../../src/dev/extensions.rst:624
msgid "└── setup.py"
msgstr ""

#: ../../../src/dev/extensions.rst:626
msgid "``extensions/axpby/`` defines the C++ extension library"
msgstr "``extensions/axpby/`` 定義 C++ 擴充程式庫"

#: ../../../src/dev/extensions.rst:627
msgid ""
"``extensions/mlx_sample_extensions`` sets out the structure for the "
"associated Python package"
msgstr "``extensions/mlx_sample_extensions`` 設定對應的 Python 軟體包結構"

#: ../../../src/dev/extensions.rst:629
msgid "``extensions/bindings.cpp`` provides Python bindings for our operation"
msgstr "``extensions/bindings.cpp`` 提供我們運算的 Python 綁定"

#: ../../../src/dev/extensions.rst:630
msgid ""
"``extensions/CMakeLists.txt`` holds CMake rules to build the library and "
"Python bindings"
msgstr ""
"``extensions/CMakeLists.txt`` 包含建置程式庫與 Python 綁定的 CMake 規則"

#: ../../../src/dev/extensions.rst:632
msgid ""
"``extensions/setup.py`` holds the ``setuptools`` rules to build and install "
"the Python package"
msgstr ""
"``extensions/setup.py`` 包含使用 ``setuptools`` 建置與安裝 Python 軟體包的規"
"則"

#: ../../../src/dev/extensions.rst:636
msgid "Binding to Python"
msgstr "綁定到 Python"

#: ../../../src/dev/extensions.rst:638
msgid ""
"We use nanobind_ to build a Python API for the C++ library. Since bindings "
"for components such as :class:`mlx.core.array`, :class:`mlx.core.stream`, "
"etc. are already provided, adding our :meth:`axpby` is simple."
msgstr ""
"我們使用 nanobind_ 為 C++ 程式庫建立 Python API。由於 :class:`mlx.core."
"array`、:class:`mlx.core.stream` 等元件已提供綁定，因此加入 :meth:`axpby` 很"
"簡單。"

#: ../../../src/dev/extensions.rst:642
msgid ""
"NB_MODULE(_ext, m) {\n"
"     m.doc() = \"Sample extension for MLX\";\n"
"\n"
"     m.def(\n"
"         \"axpby\",\n"
"         &axpby,\n"
"         \"x\"_a,\n"
"         \"y\"_a,\n"
"         \"alpha\"_a,\n"
"         \"beta\"_a,\n"
"         nb::kw_only(),\n"
"         \"stream\"_a = nb::none(),\n"
"         R\"(\n"
"             Scale and sum two vectors element-wise\n"
"             ``z = alpha * x + beta * y``\n"
"\n"
"             Follows numpy style broadcasting between ``x`` and ``y``\n"
"             Inputs are upcasted to floats if needed\n"
"\n"
"             Args:\n"
"                 x (array): Input array.\n"
"                 y (array): Input array.\n"
"                 alpha (float): Scaling factor for ``x``.\n"
"                 beta (float): Scaling factor for ``y``.\n"
"\n"
"             Returns:\n"
"                 array: ``alpha * x + beta * y``\n"
"         )\");\n"
" }"
msgstr ""

#: ../../../src/dev/extensions.rst:674
msgid ""
"Most of the complexity in the above example comes from additional bells and "
"whistles such as the literal names and doc-strings."
msgstr "上述範例的大部分複雜度來自額外的裝飾細節，例如字面名稱與文件字串。"

#: ../../../src/dev/extensions.rst:679
msgid ""
":mod:`mlx.core` must be imported before importing :mod:"
"`mlx_sample_extensions` as defined by the nanobind module above to ensure "
"that the casters for :mod:`mlx.core` components like :class:`mlx.core.array` "
"are available."
msgstr ""
"必須先匯入 :mod:`mlx.core`，再匯入以上 nanobind 模組定義的 :mod:"
"`mlx_sample_extensions`，以確保 :mod:`mlx.core` 元件（如 :class:`mlx.core."
"array`）的型別轉換器可用。"

#: ../../../src/dev/extensions.rst:687
msgid "Building with CMake"
msgstr "使用 CMake 建置"

#: ../../../src/dev/extensions.rst:689
msgid ""
"Building the C++ extension library only requires that you ``find_package(MLX "
"CONFIG)`` and then link it to your library."
msgstr ""
"建置 C++ 擴充程式庫只需要 ``find_package(MLX CONFIG)``，接著連結到你的程式庫"
"即可。"

#: ../../../src/dev/extensions.rst:692
msgid ""
"# Add library\n"
"add_library(mlx_ext)\n"
"\n"
"# Add sources\n"
"target_sources(\n"
"    mlx_ext\n"
"    PUBLIC\n"
"    ${CMAKE_CURRENT_LIST_DIR}/axpby/axpby.cpp\n"
")\n"
"\n"
"# Add include headers\n"
"target_include_directories(\n"
"    mlx_ext PUBLIC ${CMAKE_CURRENT_LIST_DIR}\n"
")\n"
"\n"
"# Link to mlx\n"
"target_link_libraries(mlx_ext PUBLIC mlx)"
msgstr ""

#: ../../../src/dev/extensions.rst:712
msgid ""
"We also need to build the attached Metal library. For convenience, we "
"provide a :meth:`mlx_build_metallib` function that builds a ``.metallib`` "
"target given sources, headers, destinations, etc. (defined in ``cmake/"
"extension.cmake`` and automatically imported with MLX package)."
msgstr ""
"我們也需要建置附帶的 Metal 程式庫。為了方便，我們提供 :meth:"
"`mlx_build_metallib` 函式，可根據來源碼、標頭、目的地等資訊建置 ``."
"metallib`` 目標（定義於 ``cmake/extension.cmake``，並在 MLX 軟體包中自動匯"
"入）。"

#: ../../../src/dev/extensions.rst:717
msgid "Here is what that looks like in practice:"
msgstr "實際用法如下："

#: ../../../src/dev/extensions.rst:719
msgid ""
"# Build metallib\n"
"if(MLX_BUILD_METAL)\n"
"\n"
"mlx_build_metallib(\n"
"    TARGET mlx_ext_metallib\n"
"    TITLE mlx_ext\n"
"    SOURCES ${CMAKE_CURRENT_LIST_DIR}/axpby/axpby.metal\n"
"    INCLUDE_DIRS ${PROJECT_SOURCE_DIR} ${MLX_INCLUDE_DIRS}\n"
"    OUTPUT_DIRECTORY ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}\n"
")\n"
"\n"
"add_dependencies(\n"
"    mlx_ext\n"
"    mlx_ext_metallib\n"
")\n"
"\n"
"endif()"
msgstr ""

#: ../../../src/dev/extensions.rst:739
msgid "Finally, we build the nanobind_ bindings"
msgstr "最後，我們建置 nanobind_ 綁定"

#: ../../../src/dev/extensions.rst:741
msgid ""
"nanobind_add_module(\n"
"  _ext\n"
"  NB_STATIC STABLE_ABI LTO NOMINSIZE\n"
"  NB_DOMAIN mlx\n"
"  ${CMAKE_CURRENT_LIST_DIR}/bindings.cpp\n"
")\n"
"target_link_libraries(_ext PRIVATE mlx_ext)\n"
"\n"
"if(BUILD_SHARED_LIBS)\n"
"  target_link_options(_ext PRIVATE -Wl,-rpath,@loader_path)\n"
"endif()"
msgstr ""

#: ../../../src/dev/extensions.rst:756
msgid "Building with ``setuptools``"
msgstr "使用 ``setuptools`` 建置"

#: ../../../src/dev/extensions.rst:758
msgid ""
"Once we have set out the CMake build rules as described above, we can use "
"the build utilities defined in :mod:`mlx.extension`:"
msgstr ""
"在依照上述說明設定 CMake 建置規則之後，我們可以使用 :mod:`mlx.extension` 中定"
"義的建置工具："

#: ../../../src/dev/extensions.rst:761
msgid ""
"from mlx import extension\n"
"from setuptools import setup\n"
"\n"
"if __name__ == \"__main__\":\n"
"    setup(\n"
"        name=\"mlx_sample_extensions\",\n"
"        version=\"0.0.0\",\n"
"        description=\"Sample C++ and Metal extensions for MLX primitives."
"\",\n"
"        ext_modules=[extension.CMakeExtension(\"mlx_sample_extensions."
"_ext\")],\n"
"        cmdclass={\"build_ext\": extension.CMakeBuild},\n"
"        packages=[\"mlx_sample_extensions\"],\n"
"        package_data={\"mlx_sample_extensions\": [\"*.so\", \"*.dylib\", \"*."
"metallib\"]},\n"
"        extras_require={\"dev\":[]},\n"
"        zip_safe=False,\n"
"        python_requires=\">=3.8\",\n"
"    )"
msgstr ""

#: ../../../src/dev/extensions.rst:781
msgid ""
"We treat ``extensions/mlx_sample_extensions`` as the package directory even "
"though it only contains a ``__init__.py`` to ensure the following:"
msgstr ""
"我們將 ``extensions/mlx_sample_extensions`` 視為軟體包目錄，即使它只包含 "
"``__init__.py``，也能確保以下事項："

#: ../../../src/dev/extensions.rst:784
msgid ":mod:`mlx.core` must be imported before importing :mod:`_ext`"
msgstr "必須先匯入 :mod:`mlx.core`，再匯入 :mod:`_ext`"

#: ../../../src/dev/extensions.rst:785
msgid ""
"The C++ extension library and the metal library are co-located with the "
"python bindings and copied together if the package is installed"
msgstr ""
"C++ 擴充程式庫與 Metal 程式庫會與 Python 綁定放在同一位置，並在安裝軟體包時一"
"併複製"

#: ../../../src/dev/extensions.rst:788
msgid ""
"To build the package, first install the build dependencies with ``pip "
"install -r requirements.txt``.  You can then build inplace for development "
"using ``python setup.py build_ext -j8 --inplace`` (in ``extensions/``)"
msgstr ""
"要建置此軟體包，請先使用 ``pip install -r requirements.txt`` 安裝建置相依。接"
"著可在 ``extensions/`` 內使用 ``python setup.py build_ext -j8 --inplace`` 進"
"行就地建置以供開發。"

#: ../../../src/dev/extensions.rst:792
msgid "This results in the directory structure:"
msgstr "結果會產生以下目錄結構："

#: ../../../src/dev/extensions.rst:796
msgid "│   ├── __init__.py"
msgstr ""

#: ../../../src/dev/extensions.rst:797
msgid "│   ├── libmlx_ext.dylib # C++ extension library"
msgstr "│   ├── libmlx_ext.dylib # C++ 擴充程式庫"

#: ../../../src/dev/extensions.rst:798
msgid "│   ├── mlx_ext.metallib # Metal library"
msgstr "│   ├── mlx_ext.metallib # Metal 程式庫"

#: ../../../src/dev/extensions.rst:799
msgid "│   └── _ext.cpython-3x-darwin.so # Python Binding"
msgstr "│   └── _ext.cpython-3x-darwin.so # Python 綁定"

#: ../../../src/dev/extensions.rst:800
msgid "..."
msgstr ""

#: ../../../src/dev/extensions.rst:802
msgid ""
"When you try to install using the command ``python -m pip install .`` (in "
"``extensions/``), the package will be installed with the same structure as "
"``extensions/mlx_sample_extensions`` and the C++ and Metal library will be "
"copied along with the Python binding since they are specified as "
"``package_data``."
msgstr ""
"當你在 ``extensions/`` 中使用 ``python -m pip install .`` 安裝時，軟體包會以 "
"``extensions/mlx_sample_extensions`` 相同的結構安裝，且因為它們被指定為 "
"``package_data``，所以 C++ 與 Metal 程式庫會與 Python 綁定一併複製。"

#: ../../../src/dev/extensions.rst:809
msgid "Usage"
msgstr "使用方式"

#: ../../../src/dev/extensions.rst:811
msgid ""
"After installing the extension as described above, you should be able to "
"simply import the Python package and play with it as you would any other MLX "
"operation."
msgstr ""
"依照上述方式安裝擴充後，你應該可以直接匯入 Python 軟體包，像使用其他 MLX 運算"
"一樣進行測試。"

#: ../../../src/dev/extensions.rst:814
msgid "Let's look at a simple script and its results:"
msgstr "讓我們看看簡單腳本及其結果："

#: ../../../src/dev/extensions.rst:816
msgid ""
"import mlx.core as mx\n"
"from mlx_sample_extensions import axpby\n"
"\n"
"a = mx.ones((3, 4))\n"
"b = mx.ones((3, 4))\n"
"c = axpby(a, b, 4.0, 2.0, stream=mx.cpu)\n"
"\n"
"print(f\"c shape: {c.shape}\")\n"
"print(f\"c dtype: {c.dtype}\")\n"
"print(f\"c correct: {mx.all(c == 6.0).item()}\")"
msgstr ""

#: ../../../src/dev/extensions.rst:829
msgid "Output:"
msgstr "輸出："

#: ../../../src/dev/extensions.rst:831
msgid ""
"c shape: [3, 4]\n"
"c dtype: float32\n"
"c correctness: True"
msgstr ""

#: ../../../src/dev/extensions.rst:838
msgid "Results"
msgstr "結果"

#: ../../../src/dev/extensions.rst:840
msgid ""
"Let's run a quick benchmark and see how our new ``axpby`` operation compares "
"with the naive :meth:`simple_axpby` we first defined on the CPU."
msgstr ""

#: ../../../src/dev/extensions.rst:843
msgid ""
"import mlx.core as mx\n"
"from mlx_sample_extensions import axpby\n"
"import time\n"
"\n"
"mx.set_default_device(mx.cpu)\n"
"\n"
"def simple_axpby(x: mx.array, y: mx.array, alpha: float, beta: float) -> mx."
"array:\n"
"    return alpha * x + beta * y\n"
"\n"
"M = 256\n"
"N = 512\n"
"\n"
"x = mx.random.normal((M, N))\n"
"y = mx.random.normal((M, N))\n"
"alpha = 4.0\n"
"beta = 2.0\n"
"\n"
"mx.eval(x, y)\n"
"\n"
"def bench(f):\n"
"    # Warm up\n"
"    for i in range(100):\n"
"        z = f(x, y, alpha, beta)\n"
"        mx.eval(z)\n"
"\n"
"    # Timed run\n"
"    s = time.time()\n"
"    for i in range(5000):\n"
"        z = f(x, y, alpha, beta)\n"
"        mx.eval(z)\n"
"    e = time.time()\n"
"    return e - s\n"
"\n"
"simple_time = bench(simple_axpby)\n"
"custom_time = bench(axpby)\n"
"\n"
"print(f\"Simple axpby: {simple_time:.3f} s | Custom axpby: {custom_time:.3f} "
"s\")"
msgstr ""

#: ../../../src/dev/extensions.rst:883
msgid ""
"The results are ``Simple axpby: 0.114 s | Custom axpby: 0.109 s``. We see "
"modest improvements right away!"
msgstr ""

#: ../../../src/dev/extensions.rst:886
msgid ""
"This operation is now good to be used to build other operations, in :class:"
"`mlx.nn.Module` calls, and also as a part of graph transformations like :"
"meth:`grad`."
msgstr ""
"這個運算現在可以用來建構其他運算、用於 :class:`mlx.nn.Module` 呼叫，也能作"
"為 :meth:`grad` 等圖轉換的一部分。"

#: ../../../src/dev/extensions.rst:891
msgid "Scripts"
msgstr "腳本"

#: ../../../src/dev/extensions.rst:893
msgid "Download the code"
msgstr "下載程式碼"

#: ../../../src/dev/extensions.rst:895
msgid ""
"The full example code is available in `mlx <https://github.com/ml-explore/"
"mlx/tree/main/examples/extensions/>`_."
msgstr ""
"完整範例程式碼可在 `mlx <https://github.com/ml-explore/mlx/tree/main/"
"examples/extensions/>`_ 取得。"

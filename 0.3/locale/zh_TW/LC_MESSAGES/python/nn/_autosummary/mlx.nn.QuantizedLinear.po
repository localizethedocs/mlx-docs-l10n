# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, MLX Contributors
# This file is distributed under the same license as the MLX package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MLX 0.3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-08 12:56+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../src/python/nn/_autosummary/mlx.nn.QuantizedLinear.rst:2
msgid "mlx.nn.QuantizedLinear"
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:1
msgid ""
"Applies an affine transformation to the input using a quantized weight "
"matrix."
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:3
msgid ""
"It is the quantized equivalent of :class:`mlx.nn.Linear`. For now its "
"parameters are frozen and will not be included in any gradient computation "
"but this will probably change in the future."
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:7
msgid ""
"QuantizedLinear also provides two useful classmethods to convert linear "
"layers to QuantizedLinear layers."
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:10
msgid ""
":meth:`from_linear` returns a QuantizedLinear layer that applies the same "
"linear transformation up to the quantization error."
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:12
msgid ""
":meth:`quantize_module` swaps all the linear layers of the passed module "
"with QuantizedLinear ones."
msgstr ""

#: ../../../src/python/nn/_autosummary/mlx.nn.QuantizedLinear.rst:0
msgid "Parameters"
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:15
msgid "The dimensionality of the input features"
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:17
msgid "The dimensionality of the output features"
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:19
msgid ""
"If set to ``False`` then the layer will not use a bias. (default: True)."
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:22
msgid ""
"The group size to use for the quantized weight. See :func:`~mlx.core."
"quantize`. (default: 64)"
msgstr ""

#: ../../../../../../.conda/lib/python3.12/site-packages/mlx/nn/layers/quantized.py:docstring
#: of mlx.nn.layers.quantized.QuantizedLinear:25
msgid ""
"The bit width to use for the quantized weight. See :func:`~mlx.core."
"quantize`. (default: 4)"
msgstr ""
